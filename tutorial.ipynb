{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用DMT训练框架\n",
    "\n",
    "通过以下4步，使用DMT框架训练并使用你自己的深度学习模型：\n",
    "1. 定义数据集\n",
    "2. 定义模型\n",
    "3. 重写训练器和测试方法\n",
    "4. 编写配置文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义数据集\n",
    "\n",
    "DMT 框架使用 `torch.utils.data.Dataset` 作为数据集的基类，唯一的限制是你只能通过传入一个 `EasyDict` 实例 `args` 参数来实例化数据集。\n",
    "\n",
    "例如在 `src_classify` 中，我们使用一个封装好的 MNIST 数据集，它带有两个自定义方法 `transforms` 和 `inv_transforms` 对数据进行归一化和逆归一化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "from src_classify.datasets import MNIST\n",
    "\n",
    "args_data = EasyDict(dict(root = \"data\", train = True))\n",
    "ds = MNIST(args_data)\n",
    "\n",
    "import random\n",
    "index = random.randint(0, len(ds))\n",
    "img, label = ds.inv_transforms()(ds[index][0]), ds[index][1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "plt.title(f\"Label: {label}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义模型\n",
    "\n",
    "DMT 框架使用 `torch.nn.Module` 作为模型的基类，同样的，你只能通过传入一个 `EasyDict` 实例 `args` 参数来实例化模型。\n",
    "\n",
    "例如在 `src_classify` 中，我们使用一个封装好的 ResNet 模型。它带有两个自定义方法 `compute_loss` 和 `predict` 分别用来在训练阶段计算损失函数和在测试阶段进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_classify.models import ResnetModel\n",
    "\n",
    "args_model = EasyDict(dict(\n",
    "    input=1, output=10, hidden_dims=[32, 64, 128]\n",
    "))\n",
    "model = ResnetModel(args_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 重写训练器和测试方法\n",
    "\n",
    "DMT框架使用自定义的 `Trainer` 作为训练器的基类，你需要继承它编写自己的训练器，并重写以下方法：\n",
    "- 必须重写的方法：\n",
    "  - `_compute_loss`：计算损失函数，返回两个字典分别记录损失函数的值和相应的权值超参数\n",
    "  - `_register_custom_metrics`：将自定义的指标名称登录到 `self.tracker` 中\n",
    "- 按需求重写的方法：\n",
    "  - `eval`: 在测试模式下需要重写，用来计算测试集上的指标\n",
    "  - `_eval_epoch`：在训练过程中计算测试指标的方法\n",
    "  - `_log_metrics`：在 `_eval_epoch` 后将测试指标写入日志文件的方法\n",
    "  - `sample`：在采样模式下需要重写，用来生成新样本\n",
    "  - `_sample_epoch`：在训练过程中生成新样本的方法\n",
    "\n",
    "例如在 `src_classify` 中，我们使用 `ClassifyTrainer` 作为训练器。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 编写配置文件\n",
    "\n",
    "DMT框架使用 *.yml* 文件对实验进行配置，配置文件分为7个部分：\n",
    "1. 实验信息：包括名称、os、gpu等信息\n",
    "2. 模型参数\n",
    "3. 数据集参数\n",
    "4. 训练过程参数：包括优化器、学习率、训练轮数等\n",
    "5. 评估过程参数：包括评估批大小等\n",
    "6. 采样过程参数\n",
    "7. 其他参数\n",
    "\n",
    "具体可参考`base_config.yml`文件。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子：使用ResNet对MNIST数据集进行手写数字分类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码目录：`./src_classify`\n",
    "\n",
    "- 工作目录: \n",
    "    ```bash\n",
    "    $ pwd\n",
    "    ~/deep-model-trainer\n",
    "    ```\n",
    "- 训练模型\n",
    "    ```bash\n",
    "    $ python src_classify/main.py --config base_config --train\n",
    "    ```\n",
    "- 断点继续训练\n",
    "    ```bash\n",
    "    $ python src_classify/main.py --config base_config --new_config resume --train \n",
    "    ```\n",
    "- tensorboard monitor\n",
    "    ```bash\n",
    "    $ tensorboard --logdir experiments/MNIST-Classification/logs --port=8008\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子：使用VQ-VAE对MNIST数据集进行手写数字生成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码目录：`./src_generate`\n",
    "\n",
    "- 工作目录: \n",
    "    ```bash\n",
    "    $ pwd\n",
    "    ~/deep-model-trainer\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi-gpu evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" accelerate launch --num_processes=2 src_example/main.py --config example --eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0,1\" accelerate launch --num_processes=2 src_example/main.py --config example --sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir experiments/MLP-ExampleDataset/logs --port=8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7, 7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "h = torch.randn(1, 1, 14, 14)\n",
    "\n",
    "downsample = torch.nn.Conv2d(1, 1, kernel_size=3, stride=2, padding=1)\n",
    "h_down = downsample(h)\n",
    "h_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 14, 14])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsample = torch.nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, padding=0)\n",
    "h_hat = upsample(h_down)\n",
    "h_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 4, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src_generate.models.encoder import Encoder, Decoder\n",
    "\n",
    "e = Encoder(1, [16, 64, 128], 2)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "h = e(x)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Decoder(1, [128, 64, 16], 28)\n",
    "x_hat = d(h)\n",
    "x_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): UpSampleLayer(\n",
       "        (_conv_1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (_conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (_conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): UpSampleLayer(\n",
       "        (_conv_1): ConvTranspose2d(64, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): ConvTranspose2d(64, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (_conv_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (_conv_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): UpSampleLayer(\n",
       "        (_conv_1): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (_conv_1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (_conv_1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_conv_2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (_bn_2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (_identity): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): CenterCrop2d()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src_generate.models.encoder import UpSampleLayer, ResidualLayer\n",
    "\n",
    "upsample = UpSampleLayer(128, 64, 3)\n",
    "res = ResidualLayer(64, 64, 3)\n",
    "res(upsample(h)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
